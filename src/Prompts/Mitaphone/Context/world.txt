# –§–∞–π–ª —Å –≥–∏—Ç—Ö–∞–±–∞ —Ä–µ–∞–¥–º–∏, –±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–æ–∫:

NeuroMita v0.011
A mod where you get to interact with Mitas controlled by neural networks. Built with Python and C# MelonMod.

Mod Server: https://discord.gg/Tu5MPFxM4P (Get help here!)

logomod3

Installation Guide
0) MelonLoader:
A universal Unity modding tool. May conflict with BepInEx-based mods.

Install via: https://melonwiki.xyz/#/?id=requirements (Version 0.6.6)
Or directly from: https://github.com/LavaGang/MelonLoader
If you have MelonLoader.Installer.exe, select Miside to patch it for Melon-based mods.
Ensure all dependencies (e.g., .NET 6.0) are installed: https://melonwiki.xyz/#/?id=requirements

1) The Mod
The mod consists of:

Python files (place anywhere, but keep them together)
C# files: MitaAI.dll and assetbundle.test (place in the Mods folder created by MelonLoader).
Final structure should look like:

Miside
- Other Miside folders
- Mods (Create if needed)
  - MitaAI.dll
  - assetbundle.test

Any Separate Folder
- _internal
- libs
- Prompts
- NeuroMita.exe
(For local voice generation, also include:)
- Models
- features.env
- include
- init_triton.bat
- init.py
Future versions may include a launcher.

Download releases here: https://github.com/VinerX/NeuroMita/releases
Actual release: https://github.com/VinerX/NeuroMita/releases/download/v0.011/NeuroMita.0.011.MitaWorld.7z

In-game controls:

Press Tab to start typing.
Press Enter to send.
2) Text Generation
The mod supports multiple text-generation methods (tested options listed below).

Free API Options:
g4f (No API keys needed)
OpenRouter (Free keys: https://openrouter.ai/settings/keys ‚Äì rate-limited)
io.net (Free keys: https://ai.io.net/ai/api-keys ‚Äì 500k tokens/day per model)
Google AI Studio (Free keys: https://aistudio.google.com/apikey ‚Äì 1500 requests/day)
Chutes.ai (Free keys: https://chutes.ai/app/api unlimited?)
Paid API Options:
OpenRouter (Wide model selection, pay-per-use)
Local Generation:
LM Studio (https://lmstudio.ai, requires strong hardware, for advanced users only)
Note: Gemini models often handle emotions better, while GPT-4o is more precise but less expressive.

Models (as of 05/05/2025)
(Subject to rapid change‚Äîcheck Discord for updates!)

G4F (No API Keys)
Good for testing, but weaker models. Enable the checkbox in the settings. If base model does not work, use button and reload.

img_1.png

Supported models (selectable via version input + restart):

gemini-1.5-flash (Most stable in 0.4.7.7)
gpt-4o-mini
gpt-4o
gemini-2.0-flash
deepseek-chat
Full list: https://github.com/xtekky/gpt4free/blob/main/docs/providers-and-models.md
OpenRouter (Free/Paid Keys)
Get keys here: https://openrouter.ai/settings/keys

img_2.png

Recommended free models:

google/gemini-2.0-pro-exp-02-05:free
deepseek/deepseek-chat:free (Best for "Kind Mita")
deepseek/deepseek-chat-v3-0324:free (Hardcore mode)
Semi-paid (requires balance but no usage cost):

google/gemini-2.5-pro-exp-03-25
Full list: https://openrouter.ai/models?max_price=0

Ai.iO (500k tokens/day per model)
API: https://api.intelligence.io.solutions/api/v1/

meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
Full list: https://docs.io.net/reference/get-started-with-io-intelligence-api
Google Ai Studio
First, go to this website: https://aistudio.google.com/. If it says your country is not supported (e.g., Russia), only then will you need Step 1. If you don‚Äôt have any regional restrictions, skip straight to Step 2.

To use it, you‚Äôll need a file called "hosts" (find it on the server for now), which must be placed in this directory: C:\Windows\System32\drivers\etc Installation steps: Download ‚Üí Copy ‚Üí Paste with replacement.

Follow this exact order‚Äîdo not move the file. THIS IS IMPORTANT, as bugs may occur otherwise.

After completing these steps, go to this website: https://aistudio.google.com/apikey, sign up, and generate an API key.

To use the model directly in the module, insert the gemini-2.0-flash model.

image

The key fields should remain empty because the key is embedded in the URL. Also, make sure to enable two checkboxes in the module:

"Via Request"

"Gemini for ProxiAPI"

Most importantly, the URL should look like this:

https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=YOUR_GENERATED_KEY_HERE Check the URL carefully‚Äîreplace the placeholder text with your actual key.

Chutes.ai
Need checkbutton "via Request", url https://llm.chutes.ai/v1/chat/completions

model deepseek-ai/DeepSeek-V3-0324
Other models - https://chutes.ai/app

3) Voice Generation
Two options: Telegram bots or local generation.

Telegram
Uses your Telegram account (preferably a secondary one) as a bot. Requires api_id and api_hash (guide: https://core.telegram.org/api/obtaining_api_id).

After setup, restart and enter the confirmation code sent to your Telegram account. If you have 2FA, enter it (invisible input).

Available bots:

@CrazyMitaAIbot (Free, unstable)
@silero_voice_bot (Paid, 600 test characters)
Note: Manually message the bots first to ensure connectivity.

Local Voice Generation
Requires the Models folder and features.env (included in releases).

Download: https://github.com/VinerX/NeuroMita/releases/download/v0.011/Models.7z
Mirror: https://drive.google.com/file/d/16S0v7qsVKGwqI1yHU_ScZ94wtZooIZqI/view?usp=drive_link
Enable voice generation.
Select Local (requires features.env).
Choose and configure a model. (Initial setup may take time due to downloads.)
For model installation details, see here

img_5.png
Credits
Developers:

VinerX
vlad2830 (C# & Python)
Nelxi (distrane25) (Voice input integration)
Local Voice Generation (Massive Contribution):

_atm4x
Character Prompts:

Feanor (feanorqq) & Tkost (Kind Mita)
Josefummi (Short-Haired Mita)
gad991 (Cap Mita)
depikoov (Sweet Mita)
Animations (WIP):

JPAV
Pull Requests & CrazyMitaBot Contact:

„Çπ„Éé„Éº (v1nn1ty)
Testers (Brave Bug Hunters):

GermanPlaygroud
Special Thanks:

Sutherex (Introduced OpenRouter, organizational help)
Dr. Couch Science (Early tester, admin support)
Romancho (Idea organization, community moderation)
FlyOfFly (Unity advice, early text input help)
LoLY3_0 (The cat on a watermelon üçâ)
Mr. Sub (Likely how you found this mod!)
All early testers (Especially smarkloker)
KASTA
Support the author (VinerX): https://boosty.to/vinerx

CryptoCurrency:

Ethereum (ETH) 0xd1b91ff711f1315053f3C89EB9256eABF3Ee0377
USDT (ETH) 0xd1b91ff711f1315053f3C89EB9256eABF3Ee0377
USDT (TRON) THi7QcfNyEmnaRzzoCpM6wyhhxvPBb5mJg
Tron (TRX) THi7QcfNyEmnaRzzoCpM6wyhhxvPBb5mJg
Bitcoin (BTC) bc1q3df4zlv40dhkhuq2asmh4we9jvqlnemey5u4cw
Write me in discord, if need address for other type.



#   –§–∞–π–ª –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–π –æ–∑–≤—É—á–∫–µ —Å –≥–∏—Ç—Ö–∞–±–∞

üõ†Ô∏è Setting up local models for voice synthesis - step-by-step guide
0. What you'll need beforehand
What	Why
Fresh version of NeuroMita.exe	0.011+
Graphics card (NVIDIA/AMD)	Minimum tested and working - 1060 3gb and RX 580
Stable internet	Models weigh from several hundred MB to several GB (future plans up to 80 GB)
10-30 minutes of free time	Depends on network speed and graphics card.
Note: if you have an Intel graphics card and want to help test local voice synthesis, please contact us on the Discord server: https://discord.gg/Tu5MPFxM4P

1. Open the model manager
Select source Local (local voice synthesis).
Click "Manage local models".
Open model manager

2. Find the needed model
In the window that appears, click on the model you want to install.

List of available models

Models and their requirements
Edge-TTS + RVC
Parameter	Value
Size	3 GB
Recommended VRAM	3GB - 4GB
Supported languages	Russian, English
Devices	CUDA / DML / CPU
Min. tested graphics card	GTX 1060 3GB / RX 580 8 GB
Recommended graphics card	16xx Ti/Super
Description	Most stable model. Best model for English language for weak/medium graphics cards. Works on principle: Edge TTS -> RVC (Retrieval-Based Voice Conversion)
Silero + RVC
Parameter	Value
Size	3 GB + 50 MB Silero package
Recommended VRAM	3GB - 4GB
Devices	CUDA / DML / CPU
Min. tested graphics card	GTX 1060 3GB / RX 580 8 GB
Recommended graphics card	16xx Ti/Super
Recommended processor (FOR AMD)	Not determined
Description	Best model for Russian language for weak/medium graphics cards. Works on principle: Silero tts -> RVC (Retrieval-Based Voice Conversion)
The models above are downloaded as a package since they depend on the same technology.

Fish Speech (regular)
Parameter	Value
Size	5 GB
Recommended VRAM	4GB-6GB
Supported languages	Russian, English, Chinese, Japanese, German, French, Spanish, Korean, Arabic, Polish, Portuguese, Italian, Dutch
Devices	CUDA / CPU
Min. tested graphics card	RTX 4060
Recommended graphics card	RTX 2080 Ti / RTX 4090
Min. tested processor	I5 13600KF - speed slightly slower than RTX 4060 without compilation (+ postfix).
Description	NOT RECOMMENDED FOR USERS WITH RTX 30xx+ GRAPHICS CARDS! USE THE (+) VERSION. Best model in the up to 6GB segment. Clones voice, repeats its style. Occasionally doesn't voice sentences due to architectural feature of the model.
Fish Speech+
Parameter	Value
Size	5 GB + 2 GB compilation components
Recommended VRAM	4GB-6GB
Supported languages	Russian, English, Chinese, Japanese, German, French, Spanish, Korean, Arabic, Polish, Portuguese, Italian, Dutch
Devices	CUDA / CPU
Min. tested graphics card	RTX 3060
Recommended graphics card	RTX 4060+
Min. tested processor	I5 13600KF - speed slightly slower than RTX 4060 without compilation (+ postfix).
Description	Best model in the up to 6GB segment. Clones voice, repeats its style. Occasionally doesn't voice sentences due to architectural feature of the model.
Fish Speech+ + RVC
Parameter	Value
Size	5 GB + 2 GB compilation components
Recommended VRAM	6GB-8GB
Supported languages	Russian, English, Chinese, Japanese, German, French, Spanish, Korean, Arabic, Polish, Portuguese, Italian, Dutch
Devices	CUDA / CPU
Min. tested graphics card	RTX 3060
Recommended graphics card	RTX 4060+
Min. tested processor	I5 13600KF - speed slightly slower than RTX 4060 without compilation (+ postfix).
Description	Currently the best model in the mod: Clones voice, repeats its style, processes it with Revoice (RVC) to reduce artifacts. SOTA for Russian language.
The Fish Speech+ + RVC model also installs Edge TTS + RVC and Silero + RVC models since it depends on the same architecture.

3. Click "Install"
A window "Installing model ..." will appear - it will show download and extraction status.

4. Monitor the installation log
Installation will be long and errors are rare.

‚ö†Ô∏è If an error appears during the process - take a screenshot or copy the log text. Without it, it will be difficult to help.

5. Configure computing device
After successful installation, a settings window will appear:

Device settings

Choose what you actually have:

CUDA:0 - NVIDIA graphics card
DML - AMD
CPU - if there's no graphics card
Click "Save".

6. Select and run the model
Option 1. Regular models
(Edge-TTS + RVC, Silero + RVC, Fish Speech)

In the main dropdown list, select the needed model.
A couple of seconds and you can start voice synthesis!
Select regular model

Option 2. Fish Speech+ (with phase correction) or Fish Speech+ + RVC
Select the model from the list.
Initialization will begin. Almost always on the first launch an error appears name 'Config' is not defined - this is normal, don't worry.
Completely close NeuroMita.exe.
Launch the program again and select the same model.
Wait for initialization to complete - now everything will work.
If something went wrong
When asking for help, please specify:

At which step of the guide did the problem occur?
PC specifications: Windows/Linux/macOS, graphics card model (NVIDIA/AMD/Intel).
Screenshots/logs:
Error at step 4? - attach the log from the "Installing model ..." window.
Error name 'Config' is not defined with Fish Speech+? - if it disappears after restart, this is normal; if it remains - send a screenshot.
Known issues:
AttributeError: module `torch` has no attribute `cuda`
Solution: Delete the /Lib/torch folder and the folder with the same name but with version. Then restart NeuroMita.exe and installation will proceed.

Very long initialization:
Solution: Make sure you set CUDA/DML everywhere, otherwise it might work on the processor, hence taking so long.

torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised: CalledProcessError: Command:
Solution:

Delete folders

1.1) C:/Users/<your_username>/.triton/cache

1.2) C:/Users/<your_username>/AppData/Local/Temp/torchinductor_<your_username>

Open the folder with NeuroMita.exe and run init_triton.bat

Wait for the script to complete

Launch NeuroMita.exe and select the model you were trying to run.